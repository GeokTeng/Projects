{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b1acf0-2736-473e-a3c4-bc615c5644eb",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "In <code>03_Model</code> notebook, we explored around 50 features to predict HDB prices using Linear Regression, Ridge Regression and Lasso Regression.\n",
    "\n",
    "In this 04 notebook, we shall explore:\n",
    "- using lesser features\n",
    "- Ensemble Methods (Random Forest & XGBoost)\n",
    "- Sequential Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca6848-553a-45d2-95d0-d682a1576e30",
   "metadata": {},
   "source": [
    "# Imports and Function creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cd902b-6fd5-44ed-91ca-61f686303f28",
   "metadata": {},
   "source": [
    "## Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de7cdc60-7e2e-49d8-b1d1-cb82bc088eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "#Visualisation:\n",
    "import seaborn               as sns\n",
    "import matplotlib.pyplot     as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "#sklearn  libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Preprocessing:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Model Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd4edd6-84f7-4f4b-875d-687ba1fa1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Neural Network\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "#Regularization\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93073e4-f463-4454-a65b-eb9f736338d7",
   "metadata": {},
   "source": [
    "## Function Creation\n",
    "### Dataframe Exploratory Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb774243-af84-4807-b748-7d4df2ed6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing missing, duplicates, shape, dtypes\n",
    "def df_summary(df):\n",
    "    print(f\"Shape(col,rows): {df.shape}\")\n",
    "    print(f\"Number of duplicates: {df.duplicated().sum()}\")\n",
    "    print('---'*20)\n",
    "    print(f'Number of each unqiue datatypes:\\n{df.dtypes.value_counts()}')\n",
    "    print('---'*20)\n",
    "    print(\"Columns with missing values:\")\n",
    "    isnull_df = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "    isnull_df.columns = ['col','num_nulls']\n",
    "    isnull_df['perc_null'] = ((isnull_df['num_nulls'])/(len(df))).round(2)\n",
    "    _df_ = isnull_df[isnull_df['num_nulls']>0]\n",
    "    if _df_.empty:\n",
    "        print(\"--No Missing Data--\")\n",
    "    else:\n",
    "        print(_df_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d00a7-3996-4f10-abf0-e8d877b5dca7",
   "metadata": {},
   "source": [
    "### Modelling Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff809787-6850-4858-ad29-18b0237a6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Preprocessing\n",
    "\n",
    "def onehotenc_df (train,test):\n",
    "    enc = OneHotEncoder(drop = 'first', handle_unknown = 'ignore')\n",
    "    train = enc.fit_transform(train)\n",
    "    test = enc.transform(test)\n",
    "    \n",
    "    output_col_names = list(enc.get_feature_names_out())\n",
    "    train_df = pd.DataFrame(train.toarray(), columns = output_col_names)\n",
    "    test_df = pd.DataFrame(test.toarray(), columns = output_col_names)\n",
    "    return (train_df,test_df)\n",
    "\n",
    "def standardscaler_df (train,test):\n",
    "    ss = StandardScaler()\n",
    "    train = ss.fit_transform(train)\n",
    "    test = ss.transform(test)\n",
    "    \n",
    "    output_col_names = list(ss.get_feature_names_out())\n",
    "    train_df = pd.DataFrame(train, columns = output_col_names)\n",
    "    test_df = pd.DataFrame(test, columns = output_col_names)\n",
    "    return (train_df,test_df)\n",
    "\n",
    "#Regularization. return a data frame with features and respective coefficient\n",
    "def feature_coef_ (model):\n",
    "    coef_list = list(model.coef_)\n",
    "    feature_list = list(model.feature_names_in_)\n",
    "    feature_coef_df = pd.DataFrame({'Features':feature_list,'Coeffiecient':coef_list})\n",
    "    return feature_coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f61c1-4319-46eb-b6b1-1723e0076c2d",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0b55a8-d2d1-48df-be61-24679303aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/modelling_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bffddff-d02f-4ce3-b0b3-276c011fcb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape(col,rows): (150634, 52)\n",
      "Number of duplicates: 362\n",
      "------------------------------------------------------------\n",
      "Number of each unqiue datatypes:\n",
      "int64      26\n",
      "float64    14\n",
      "object     12\n",
      "dtype: int64\n",
      "------------------------------------------------------------\n",
      "Columns with missing values:\n",
      "--No Missing Data--\n"
     ]
    }
   ],
   "source": [
    "df_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a882e6-94ee-4502-965b-2c0d724e48d6",
   "metadata": {},
   "source": [
    "**Remarks**<br>\n",
    "- May ignore number of duplicates (flat ID was dropped in initial dataset transformation, and previously confirmed no duplication)\n",
    "- It is normal to have duplicates as there are flats with similar features\n",
    "- No missing values in this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc8985-831f-4055-9166-0ddd72653420",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1: Preprocessing<a class=\"anchor\" id=\"ID1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838e7dc5-fd7f-4602-a6ea-4ff9c8f6952f",
   "metadata": {},
   "source": [
    "**Let's first analyse the number of unique elements each categorical feature has**:<br>\n",
    "\n",
    "Having large number of unique elements will post concern for computational memory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad88b6bf-4111-48ce-9c7b-fc2b9c4e4890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Categorical feature Tranc_YearMonth, \n",
      "there is 110 number of unique elements.\n",
      "\n",
      "For Categorical feature town, \n",
      "there is 26 number of unique elements.\n",
      "\n",
      "For Categorical feature flat_type, \n",
      "there is 7 number of unique elements.\n",
      "\n",
      "For Categorical feature street_name, \n",
      "there is 553 number of unique elements.\n",
      "\n",
      "For Categorical feature storey_range, \n",
      "there is 17 number of unique elements.\n",
      "\n",
      "For Categorical feature flat_model, \n",
      "there is 20 number of unique elements.\n",
      "\n",
      "For Categorical feature address, \n",
      "there is 9157 number of unique elements.\n",
      "\n",
      "For Categorical feature planning_area, \n",
      "there is 32 number of unique elements.\n",
      "\n",
      "For Categorical feature mrt_name, \n",
      "there is 94 number of unique elements.\n",
      "\n",
      "For Categorical feature bus_stop_name, \n",
      "there is 1657 number of unique elements.\n",
      "\n",
      "For Categorical feature pri_sch_name, \n",
      "there is 177 number of unique elements.\n",
      "\n",
      "For Categorical feature sec_sch_name, \n",
      "there is 134 number of unique elements.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = df.select_dtypes(include='object').columns.tolist()\n",
    "for col in _:\n",
    "    print(f\"For Categorical feature {col}, \\nthere is {df[col].nunique()} number of unique elements.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4c632-a7b5-499e-b9fa-172c47769f44",
   "metadata": {},
   "source": [
    "**Reducing Features used for modelling**\n",
    "\n",
    "These features are selected based on general sense their relevance in influencing HDB price. <code>address</code> is excluded in consideration of the computational needs if we were to include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98178479-cd8e-4de4-b52b-eaa2b1d13e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tranc_YearMonth</th>\n",
       "      <th>Tranc_Year</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>street_name</th>\n",
       "      <th>mid_storey</th>\n",
       "      <th>floor_area_sqft</th>\n",
       "      <th>hdb_age</th>\n",
       "      <th>mrt_name</th>\n",
       "      <th>pri_sch_name</th>\n",
       "      <th>sec_sch_name</th>\n",
       "      <th>Hawker_Nearest_Distance</th>\n",
       "      <th>mrt_nearest_distance</th>\n",
       "      <th>pri_sch_nearest_distance</th>\n",
       "      <th>sec_sch_nearest_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>Model A</td>\n",
       "      <td>UPP BOON KENG RD</td>\n",
       "      <td>11.0</td>\n",
       "      <td>968.760</td>\n",
       "      <td>15</td>\n",
       "      <td>Kallang</td>\n",
       "      <td>Geylang Methodist School</td>\n",
       "      <td>Geylang Methodist School</td>\n",
       "      <td>154.753357</td>\n",
       "      <td>330.083069</td>\n",
       "      <td>1138.633422</td>\n",
       "      <td>1138.633422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>Improved</td>\n",
       "      <td>BISHAN ST 13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1399.320</td>\n",
       "      <td>34</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>Kuo Chuan Presbyterian Primary School</td>\n",
       "      <td>Kuo Chuan Presbyterian Secondary School</td>\n",
       "      <td>640.151925</td>\n",
       "      <td>903.659703</td>\n",
       "      <td>415.607357</td>\n",
       "      <td>447.894399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013</td>\n",
       "      <td>EXECUTIVE</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>BT BATOK ST 25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1550.016</td>\n",
       "      <td>24</td>\n",
       "      <td>Bukit Batok</td>\n",
       "      <td>Keming Primary School</td>\n",
       "      <td>Yusof Ishak Secondary School</td>\n",
       "      <td>1762.082341</td>\n",
       "      <td>1334.251197</td>\n",
       "      <td>498.849039</td>\n",
       "      <td>180.074558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>2012</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>Model A</td>\n",
       "      <td>BISHAN ST 22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1108.692</td>\n",
       "      <td>29</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>Catholic High School</td>\n",
       "      <td>Catholic High School</td>\n",
       "      <td>726.215262</td>\n",
       "      <td>907.453484</td>\n",
       "      <td>389.515528</td>\n",
       "      <td>389.515528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>Simplified</td>\n",
       "      <td>YISHUN ST 81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>893.412</td>\n",
       "      <td>34</td>\n",
       "      <td>Khatib</td>\n",
       "      <td>Naval Base Primary School</td>\n",
       "      <td>Orchid Park Secondary School</td>\n",
       "      <td>1540.151439</td>\n",
       "      <td>412.343032</td>\n",
       "      <td>401.200584</td>\n",
       "      <td>312.025435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tranc_YearMonth  Tranc_Year  flat_type  flat_model       street_name  \\\n",
       "0      2016-05-01        2016     4 ROOM     Model A  UPP BOON KENG RD   \n",
       "1      2012-07-01        2012     5 ROOM    Improved      BISHAN ST 13   \n",
       "2      2013-07-01        2013  EXECUTIVE   Apartment    BT BATOK ST 25   \n",
       "3      2012-04-01        2012     4 ROOM     Model A      BISHAN ST 22   \n",
       "4      2017-12-01        2017     4 ROOM  Simplified      YISHUN ST 81   \n",
       "\n",
       "   mid_storey  floor_area_sqft  hdb_age     mrt_name  \\\n",
       "0        11.0          968.760       15      Kallang   \n",
       "1         8.0         1399.320       34       Bishan   \n",
       "2        14.0         1550.016       24  Bukit Batok   \n",
       "3         5.0         1108.692       29       Bishan   \n",
       "4         2.0          893.412       34       Khatib   \n",
       "\n",
       "                            pri_sch_name  \\\n",
       "0               Geylang Methodist School   \n",
       "1  Kuo Chuan Presbyterian Primary School   \n",
       "2                  Keming Primary School   \n",
       "3                   Catholic High School   \n",
       "4              Naval Base Primary School   \n",
       "\n",
       "                              sec_sch_name  Hawker_Nearest_Distance  \\\n",
       "0                 Geylang Methodist School               154.753357   \n",
       "1  Kuo Chuan Presbyterian Secondary School               640.151925   \n",
       "2             Yusof Ishak Secondary School              1762.082341   \n",
       "3                     Catholic High School               726.215262   \n",
       "4             Orchid Park Secondary School              1540.151439   \n",
       "\n",
       "   mrt_nearest_distance  pri_sch_nearest_distance  sec_sch_nearest_dist  \n",
       "0            330.083069               1138.633422           1138.633422  \n",
       "1            903.659703                415.607357            447.894399  \n",
       "2           1334.251197                498.849039            180.074558  \n",
       "3            907.453484                389.515528            389.515528  \n",
       "4            412.343032                401.200584            312.025435  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selected_features = [\n",
    "    'Tranc_YearMonth',\n",
    "    'Tranc_Year',\n",
    "    'flat_type',\n",
    "    'flat_model',\n",
    "    'street_name',\n",
    "    'mid_storey',\n",
    "   'floor_area_sqft',\n",
    "    'hdb_age',\n",
    "    'mrt_name',\n",
    "    'pri_sch_name',\n",
    "    'sec_sch_name',\n",
    "    'Hawker_Nearest_Distance',\n",
    "    'mrt_nearest_distance',\n",
    "    'pri_sch_nearest_distance',\n",
    "    'sec_sch_nearest_dist']\n",
    "sub_df = df.copy()\n",
    "sub_df = sub_df.loc[:,Selected_features]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3872c77-f0d9-4e1c-b500-54eb3f779ab8",
   "metadata": {},
   "source": [
    "## 1.1 Train_test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2d30e9-2f44-452a-9d3a-b334d17b2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['resale_price']\n",
    "X = df.loc[:,Selected_features]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=23)\n",
    "\n",
    "#reset index\n",
    "for _df_ in [X_train, X_test, y_train, y_test]:\n",
    "    _df_.reset_index(inplace=True,drop=True)\n",
    "\n",
    "X_train_obj = X_train.select_dtypes(include='object')\n",
    "X_train_numeric = X_train.select_dtypes(exclude='object')\n",
    "\n",
    "X_test_obj = X_test.select_dtypes(include='object')\n",
    "X_test_numeric = X_test.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e0c5f-46fe-4677-bad3-e1621d924dc6",
   "metadata": {},
   "source": [
    "## 1.2 Categorical Data - Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "934a3bc1-3919-4dd8-aac2-f972b75bfdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_enc,X_test_enc) = onehotenc_df(X_train_obj,X_test_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dcb27b7-786d-4c1e-8e59-4b7ad6eb7b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique elements in categorical columns originally: 1095\n"
     ]
    }
   ],
   "source": [
    "_=X_train_obj.columns.tolist()\n",
    "Numb_1=0\n",
    "for i in _:\n",
    "    x = df[i].nunique()\n",
    "    Numb_1=Numb_1+x\n",
    "print(f\"Total number of unique elements in categorical columns originally: {Numb_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2269cd27-a016-4c50-82dc-748d7a89dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique elements in categorical columns in Train set: 1095\n"
     ]
    }
   ],
   "source": [
    "Numb_2=0\n",
    "for i in _:\n",
    "    x = X_train_obj[i].nunique()\n",
    "    Numb_2=Numb_2+x\n",
    "print(f\"Total number of unique elements in categorical columns in Train set: {Numb_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de7285b-a01e-420d-9086-9704aa86401d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique elements in categorical columns in Test set but not in Train set: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique elements in categorical columns in Test set but not in Train set: {Numb_1-Numb_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb419a-df89-432c-98bb-d1c23308564c",
   "metadata": {},
   "source": [
    "## 1.3 Numerical Data - Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c103c8-2d18-4499-8a65-c8008f113a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_ss,X_test_ss) = standardscaler_df (X_train_numeric,X_test_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e184f29-c7c6-449d-b2fa-e0a8ca5ec1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112975, 1096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(37659, 1096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat(objs = [X_train_enc, X_train_ss], axis = 1)\n",
    "X_train.shape\n",
    "\n",
    "X_test = pd.concat(objs = [X_test_enc, X_test_ss], axis = 1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e18ca3-387c-4e4c-a0bc-8ef208c6252c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 2 Modelling<a class=\"anchor\" id=\"ID2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4bbb8-ef9b-4f7d-93c8-6be99df66e42",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72a18a90-6696-4299-9fe7-bf2d4076025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.3 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b00b0-6f2b-4823-b583-55b5d6b6c29c",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1c57172-5384-42f1-a0ee-6f869d53d3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338566882114003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9322580637076259"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R2 score\n",
    "lr.score(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dabe5e4-1d82-4830-b137-30b69a33e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.4 s\n",
      "Wall time: 46.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.6007019027458285e+17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Cross validation score:\n",
    "cross_val_score(lr, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9401438b-61e6-497f-9fc1-ae25004a2c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36897.90951912104"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37171.84640748686"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE train score\n",
    "y_train_pred = lr.predict(X_train)\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "#RMSE test score\n",
    "y_test_pred = lr.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6bf61-7008-47e5-8eaa-df4d12841fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e964b16-fd8c-47ae-bf71-bd25d07826e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55.1 s\n",
      "Wall time: 55.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeCV(alphas=[0.1, 1, 10], cv=5, scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV(alphas=[0.1, 1, 10], cv=5, scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeCV(alphas=[0.1, 1, 10], cv=5, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Define the alpha values to be considered\n",
    "alphas = [0.1, 1, 10]\n",
    "\n",
    "# Define the model/estimator\n",
    "RidgeCV= RidgeCV(alphas=alphas, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Fit the model\n",
    "RidgeCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3f051c2-e279-47f6-af66-85e19169998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha = RidgeCV.alpha_\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ae574-9a7a-4093-978b-a5593497294e",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dddf67d-e651-42ce-b3a1-4f15007a39ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338858603527909"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9323137400587019"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R2 score\n",
    "RidgeCV.score(X_train, y_train)\n",
    "RidgeCV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3a8e640-2fbe-403e-b39e-7f59b816d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323985972891056"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross validation score:\n",
    "Ridge = Ridge(alpha = best_alpha)\n",
    "cross_val_score(Ridge, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb93fbf1-761f-4f3b-8f9d-bd12eb5271ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36889.77181241532"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37156.56770198522"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE train score\n",
    "y_train_pred = RidgeCV.predict(X_train)\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "#RMSE test score\n",
    "y_test_pred = RidgeCV.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb375a-5260-49e4-a333-13f89842308f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3 LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "686a729c-234f-4864-8622-2bb95f79f721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 44 s\n",
      "Wall time: 44.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(max_iter=10000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "LassoCV = LassoCV(max_iter=10000)\n",
    "LassoCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d394aa6f-42e9-4a6f-9315-2701753e3a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.03072445106098"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LassoCV.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5ba05-3576-415d-bfb0-226076426275",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8187c0b-7ff4-48e6-839e-833b11511883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8955634791147347"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8951002869244454"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LassoCV.score(X_train, y_train)\n",
    "LassoCV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4faac7aa-a226-455c-9da8-721c26ccad36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46364.43707822712"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "46256.46936111985"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE train score\n",
    "y_train_pred = LassoCV.predict(X_train)\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "#RMSE test score\n",
    "y_test_pred = LassoCV.predict(X_test)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f50eb-f171-4774-abc1-ac49e96e908f",
   "metadata": {},
   "source": [
    "## 2.4 Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d255b65-7503-4011-a3f2-db59461a9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=0, max_depth=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee0eac26-28fe-4efb-b7fc-6b8372ad6913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9min 40s\n",
      "Wall time: 9min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=17, oob_score=True, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=17, oob_score=True, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=17, oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5fae762f-0823-4b51-9ec9-fc56ff70c1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512557263176619"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9354607803203829"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train,y_train)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3fe0f81f-2ec1-49fb-81da-456c344f53c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31675.289672198356"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "36282.49850630546"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# RMSE\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82f59a-5572-465a-817f-6baad1974f26",
   "metadata": {},
   "source": [
    "## 2.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1bfec613-3259-4dfc-8580-2d57998ba137",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmatrix_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dmatrix_test = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a076b86a-acab-4ad8-8ad4-23ca93090f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid Search Parameters\n",
    "# grid_search_params = {\n",
    "#     'colsample_bytree': [0.3, 0.7, 1],\n",
    "#     'learning_rate': [0.01, 0.1, 0.5],\n",
    "#     'n_estimators': [100],\n",
    "#     'subsample': [0.5, 0.75],\n",
    "#     'max_depth': [15,25,50]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d802f65b-9186-49e5-bd93-0a791c087f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Parameters\n",
    "grid_search_params = {\n",
    "    'colsample_bytree': [0.5, 1],\n",
    "    'n_estimators': [100],\n",
    "    'subsample': [0.75],\n",
    "    'max_depth': [10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a876967-5da7-4822-9dd7-c79bd625ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_grid_reg = xgb.XGBRegressor(objective= \"reg:squarederror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fe951e2f-88d4-4aec-a66e-452b1b5debf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=xg_grid_reg,\n",
    "                    param_grid=grid_search_params,\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    cv=3,\n",
    "                    verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1971bbd1-aa32-4611-a207-ffce4546d194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV 1/3] END colsample_bytree=0.5, max_depth=10, n_estimators=100, subsample=0.75;, score=-771275793.574 total time= 3.0min\n",
      "[CV 2/3] END colsample_bytree=0.5, max_depth=10, n_estimators=100, subsample=0.75;, score=-773079915.244 total time= 3.0min\n",
      "[CV 3/3] END colsample_bytree=0.5, max_depth=10, n_estimators=100, subsample=0.75;, score=-772128876.642 total time= 3.0min\n",
      "[CV 1/3] END colsample_bytree=0.5, max_depth=20, n_estimators=100, subsample=0.75;, score=-734258867.256 total time= 6.2min\n",
      "[CV 2/3] END colsample_bytree=0.5, max_depth=20, n_estimators=100, subsample=0.75;, score=-734928747.552 total time= 6.2min\n",
      "[CV 3/3] END colsample_bytree=0.5, max_depth=20, n_estimators=100, subsample=0.75;, score=-743366090.818 total time= 6.2min\n",
      "[CV 1/3] END colsample_bytree=1, max_depth=10, n_estimators=100, subsample=0.75;, score=-757070374.440 total time= 5.6min\n",
      "[CV 2/3] END colsample_bytree=1, max_depth=10, n_estimators=100, subsample=0.75;, score=-765327936.544 total time= 5.6min\n",
      "[CV 3/3] END colsample_bytree=1, max_depth=10, n_estimators=100, subsample=0.75;, score=-745216666.614 total time= 5.7min\n",
      "[CV 1/3] END colsample_bytree=1, max_depth=20, n_estimators=100, subsample=0.75;, score=-766411542.611 total time=11.5min\n",
      "[CV 2/3] END colsample_bytree=1, max_depth=20, n_estimators=100, subsample=0.75;, score=-759863402.798 total time=11.4min\n",
      "[CV 3/3] END colsample_bytree=1, max_depth=20, n_estimators=100, subsample=0.75;, score=-750391885.937 total time=11.4min\n",
      "GridSearchCV\n",
      "Best parameters found:  {'colsample_bytree': 0.5, 'max_depth': 20, 'n_estimators': 100, 'subsample': 0.75}\n",
      "Lowest RMSE found:  27157.280826241255\n",
      "CPU times: total: 1h 27min 11s\n",
      "Wall time: 1h 28min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"GridSearchCV\")\n",
    "print(\"Best parameters found: \", grid.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "677d6eab-ca99-4efc-8332-9725eb30d805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10792.613424582221"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "25745.857109106822"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = grid.predict(X_train)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "# RMSE\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d8bb7cf9-6d78-449c-b8dc-f20230241908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9943410526126812"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9675029418730301"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_train, y_train_pred)\n",
    "metrics.r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f0ff0f5f-c16f-45cd-bce4-5e5a3ef8c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 29s\n",
      "Wall time: 4min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xg_reg = xgb.XGBRegressor(objective = \"reg:squarederror\",\n",
    "                          colsample_bytree = 0.5,\n",
    "                          subsample = 0.75,\n",
    "                          max_depth = 10)\n",
    "xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "37a08894-da4a-4c96-97e6-bd00fc8913cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21814.291212091466"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "26742.492773389706"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9768812352315115"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9649382884652431"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = xg_reg.predict(X_train)\n",
    "y_test_pred = xg_reg.predict(X_test)\n",
    "\n",
    "# RMSE\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n",
    "# R2\n",
    "metrics.r2_score(y_train, y_train_pred)\n",
    "metrics.r2_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c8f37-4722-4af3-9e10-d5c1baf6e451",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.6 Sequential Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "571de83d-b159-4314-9bb7-6457fa112d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 1000)              1097000   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,598,001\n",
      "Trainable params: 1,598,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_input = len(X_train.columns)\n",
    "\n",
    "# Instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Dense layers\n",
    "# 1st hidden layer\n",
    "model.add(Dense(1000, \n",
    "                input_shape=(n_input,), \n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd hidden layer\n",
    "model.add(Dense(500, \n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#Outputlayer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Check if your model architecture was built correctly using 'summary()'\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91627d42-cd82-428a-be62-636aa1e3c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0, \n",
    "                           patience=5, \n",
    "                           mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dcc869c6-14fa-4db4-b9b0-21b267a13ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an optimizer\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "# compile model with loss of Mean Squared Error (regression problem), specify as 'mse' for Keras to recognize\n",
    "# metric choice used here: Mean Absolute Error (other metric options: https://keras.io/api/metrics/)\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71f6d692-d4a7-44ec-b2b6-e83b168a56b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 5s 344ms/step - loss: 222447697920.0000 - mae: 449293.2188 - val_loss: 221755326464.0000 - val_mae: 448729.8750\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 222412914688.0000 - mae: 449255.2188 - val_loss: 221687808000.0000 - val_mae: 448656.3750\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 222302994432.0000 - mae: 449136.3750 - val_loss: 221506617344.0000 - val_mae: 448461.0625\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 3s 289ms/step - loss: 222041751552.0000 - mae: 448856.1250 - val_loss: 221119676416.0000 - val_mae: 448046.5938\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 221525966848.0000 - mae: 448305.5625 - val_loss: 220409626624.0000 - val_mae: 447289.0312\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 3s 285ms/step - loss: 220629532672.0000 - mae: 447351.1875 - val_loss: 219240611840.0000 - val_mae: 446043.4062\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 219208777728.0000 - mae: 445839.4688 - val_loss: 217464160256.0000 - val_mae: 444148.2812\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 217114411008.0000 - mae: 443604.4375 - val_loss: 214928900096.0000 - val_mae: 441433.8125\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 214194569216.0000 - mae: 440476.2500 - val_loss: 211484770304.0000 - val_mae: 437724.0000\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 210301468672.0000 - mae: 436272.0938 - val_loss: 206992162816.0000 - val_mae: 432841.9062\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 205309952000.0000 - mae: 430828.5312 - val_loss: 201331965952.0000 - val_mae: 426615.7188\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 199104249856.0000 - mae: 423962.3750 - val_loss: 194413101056.0000 - val_mae: 418882.7812\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 3s 292ms/step - loss: 191605669888.0000 - mae: 415519.2188 - val_loss: 186190954496.0000 - val_mae: 409504.2188\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 3s 294ms/step - loss: 182801285120.0000 - mae: 405384.5312 - val_loss: 176642326528.0000 - val_mae: 398341.5000\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 172695420928.0000 - mae: 393441.2812 - val_loss: 165818662912.0000 - val_mae: 385298.3438\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 161321615360.0000 - mae: 379539.7188 - val_loss: 153806962688.0000 - val_mae: 370291.5312\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 148882833408.0000 - mae: 363707.3750 - val_loss: 140788989952.0000 - val_mae: 353307.0938\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 135477878784.0000 - mae: 345855.8750 - val_loss: 126985076736.0000 - val_mae: 334357.2812\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 3s 292ms/step - loss: 121412427776.0000 - mae: 326058.5312 - val_loss: 112678043648.0000 - val_mae: 313512.0000\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 107005444096.0000 - mae: 304474.8750 - val_loss: 98206588928.0000 - val_mae: 290916.4375\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 92661522432.0000 - mae: 281278.7812 - val_loss: 83950223360.0000 - val_mae: 266801.4688\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 78560854016.0000 - mae: 256522.3906 - val_loss: 70306275328.0000 - val_mae: 241494.4688\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 65352822784.0000 - mae: 230888.6094 - val_loss: 57633050624.0000 - val_mae: 215393.7656\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 53247549440.0000 - mae: 204645.5156 - val_loss: 46241189888.0000 - val_mae: 188990.3438\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 42551967744.0000 - mae: 178462.2031 - val_loss: 36383436800.0000 - val_mae: 162986.4688\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 33472032768.0000 - mae: 153123.4844 - val_loss: 28173697024.0000 - val_mae: 138159.8125\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 26016702464.0000 - mae: 129589.2734 - val_loss: 21646491648.0000 - val_mae: 115731.0469\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 4s 296ms/step - loss: 20214018048.0000 - mae: 109410.4609 - val_loss: 16685135872.0000 - val_mae: 96955.0234\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 15851620352.0000 - mae: 93264.2422 - val_loss: 13078450176.0000 - val_mae: 82567.7500\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 12818231296.0000 - mae: 81627.1016 - val_loss: 10564263936.0000 - val_mae: 72467.5547\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 10722739200.0000 - mae: 73615.9453 - val_loss: 8862091264.0000 - val_mae: 65815.3984\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 3s 293ms/step - loss: 9285482496.0000 - mae: 68398.9375 - val_loss: 7719201792.0000 - val_mae: 61530.0586\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 8317811712.0000 - mae: 65178.0508 - val_loss: 6939422720.0000 - val_mae: 58771.0156\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 7679600640.0000 - mae: 63031.3867 - val_loss: 6385716736.0000 - val_mae: 56859.2266\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 7181008384.0000 - mae: 61235.8672 - val_loss: 5968855552.0000 - val_mae: 55376.0977\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 6853700608.0000 - mae: 60239.9492 - val_loss: 5629266944.0000 - val_mae: 54093.8086\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 6610203648.0000 - mae: 59367.0547 - val_loss: 5338340352.0000 - val_mae: 52911.1562\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 3s 293ms/step - loss: 6256679424.0000 - mae: 57916.5820 - val_loss: 5081176576.0000 - val_mae: 51751.4766\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 6058114560.0000 - mae: 57047.9766 - val_loss: 4847298048.0000 - val_mae: 50614.7656\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 5822526464.0000 - mae: 56125.6328 - val_loss: 4632336384.0000 - val_mae: 49508.3047\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 5624561664.0000 - mae: 55196.6914 - val_loss: 4433884160.0000 - val_mae: 48434.2070\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 5436555776.0000 - mae: 54231.1641 - val_loss: 4250148864.0000 - val_mae: 47411.1055\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 5296255488.0000 - mae: 53493.1523 - val_loss: 4079922432.0000 - val_mae: 46425.1680\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 5089230848.0000 - mae: 52543.3203 - val_loss: 3921376000.0000 - val_mae: 45508.5391\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 4953762304.0000 - mae: 51773.9102 - val_loss: 3773785344.0000 - val_mae: 44634.9336\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 4808182272.0000 - mae: 51130.6055 - val_loss: 3636087296.0000 - val_mae: 43789.9844\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 4704272896.0000 - mae: 50483.8828 - val_loss: 3507269376.0000 - val_mae: 43003.0938\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 4550265856.0000 - mae: 49705.7656 - val_loss: 3387001600.0000 - val_mae: 42263.5469\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 4432535040.0000 - mae: 49113.5625 - val_loss: 3274657792.0000 - val_mae: 41573.2461\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 4315681792.0000 - mae: 48531.4648 - val_loss: 3169980928.0000 - val_mae: 40910.2109\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 4233121280.0000 - mae: 47957.4609 - val_loss: 3072456448.0000 - val_mae: 40281.9961\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 4145946880.0000 - mae: 47547.9570 - val_loss: 2981132544.0000 - val_mae: 39696.2656\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 4065569280.0000 - mae: 47093.8125 - val_loss: 2896335872.0000 - val_mae: 39126.2461\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 3966276608.0000 - mae: 46652.5703 - val_loss: 2816515328.0000 - val_mae: 38599.4062\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 3898740224.0000 - mae: 46184.3906 - val_loss: 2741878528.0000 - val_mae: 38101.0938\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3824978944.0000 - mae: 45726.6602 - val_loss: 2672605952.0000 - val_mae: 37635.9727\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3735713280.0000 - mae: 45402.2539 - val_loss: 2607820288.0000 - val_mae: 37188.8750\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3689628928.0000 - mae: 45032.0938 - val_loss: 2547127808.0000 - val_mae: 36769.5781\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 3636134400.0000 - mae: 44724.8477 - val_loss: 2490206464.0000 - val_mae: 36370.0273\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3564397568.0000 - mae: 44338.8789 - val_loss: 2437359872.0000 - val_mae: 35995.9297\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 3526773248.0000 - mae: 44165.9141 - val_loss: 2387461120.0000 - val_mae: 35650.7617\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 3489278976.0000 - mae: 43895.8281 - val_loss: 2340697344.0000 - val_mae: 35335.1953\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3440409088.0000 - mae: 43646.7695 - val_loss: 2296655616.0000 - val_mae: 35025.1172\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3363006976.0000 - mae: 43258.9570 - val_loss: 2255439616.0000 - val_mae: 34722.1094\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3330145280.0000 - mae: 43072.4297 - val_loss: 2217037824.0000 - val_mae: 34435.5195\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3310559488.0000 - mae: 42918.5391 - val_loss: 2181342976.0000 - val_mae: 34175.2305\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3278702592.0000 - mae: 42692.4531 - val_loss: 2147176704.0000 - val_mae: 33931.8672\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 3248354816.0000 - mae: 42606.2266 - val_loss: 2115256832.0000 - val_mae: 33688.4570\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 3208285440.0000 - mae: 42325.9688 - val_loss: 2085159936.0000 - val_mae: 33469.7227\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 3184539392.0000 - mae: 42128.6953 - val_loss: 2057302400.0000 - val_mae: 33256.3086\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 3161110272.0000 - mae: 42131.6211 - val_loss: 2030930176.0000 - val_mae: 33062.7188\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 3106437888.0000 - mae: 41727.5078 - val_loss: 2006488960.0000 - val_mae: 32871.6992\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 3102799104.0000 - mae: 41729.9336 - val_loss: 1983139840.0000 - val_mae: 32700.9316\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 3098150656.0000 - mae: 41718.5469 - val_loss: 1960987904.0000 - val_mae: 32528.4805\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 3034566912.0000 - mae: 41368.1133 - val_loss: 1940139136.0000 - val_mae: 32372.2871\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 3032437760.0000 - mae: 41312.7500 - val_loss: 1920590976.0000 - val_mae: 32231.1133\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 3010667520.0000 - mae: 41195.3281 - val_loss: 1901840640.0000 - val_mae: 32080.2285\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2981469952.0000 - mae: 41105.9570 - val_loss: 1884073728.0000 - val_mae: 31952.0039\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2986431232.0000 - mae: 41058.9648 - val_loss: 1867286400.0000 - val_mae: 31825.5508\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2964389120.0000 - mae: 40893.1680 - val_loss: 1851551616.0000 - val_mae: 31709.0957\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2958019072.0000 - mae: 40937.6719 - val_loss: 1836690304.0000 - val_mae: 31597.1523\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2942576128.0000 - mae: 40809.1680 - val_loss: 1823445376.0000 - val_mae: 31480.7461\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2921992448.0000 - mae: 40737.7695 - val_loss: 1810472064.0000 - val_mae: 31379.6465\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2915221504.0000 - mae: 40603.5859 - val_loss: 1797949696.0000 - val_mae: 31274.4219\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2916474368.0000 - mae: 40648.1211 - val_loss: 1786044928.0000 - val_mae: 31171.7227\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2881067776.0000 - mae: 40464.7500 - val_loss: 1775138688.0000 - val_mae: 31077.2402\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2873588224.0000 - mae: 40395.5352 - val_loss: 1764432384.0000 - val_mae: 31004.0176\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2870899968.0000 - mae: 40409.2930 - val_loss: 1754474752.0000 - val_mae: 30926.8691\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2873915392.0000 - mae: 40352.9648 - val_loss: 1745244672.0000 - val_mae: 30848.6426\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2867816192.0000 - mae: 40331.9961 - val_loss: 1736592384.0000 - val_mae: 30772.5547\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2834590208.0000 - mae: 40130.2148 - val_loss: 1727988992.0000 - val_mae: 30698.5332\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2836102656.0000 - mae: 40180.7266 - val_loss: 1719530240.0000 - val_mae: 30638.5762\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2815117568.0000 - mae: 40006.6172 - val_loss: 1711310720.0000 - val_mae: 30567.0488\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2820940544.0000 - mae: 40004.0664 - val_loss: 1703698048.0000 - val_mae: 30513.6992\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2800772096.0000 - mae: 39870.9922 - val_loss: 1696447616.0000 - val_mae: 30459.2617\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2782005504.0000 - mae: 39872.7773 - val_loss: 1689484416.0000 - val_mae: 30401.6777\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2782258432.0000 - mae: 39786.1445 - val_loss: 1683191680.0000 - val_mae: 30335.2832\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2785085952.0000 - mae: 39905.7773 - val_loss: 1677450240.0000 - val_mae: 30276.0469\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2772855808.0000 - mae: 39746.4219 - val_loss: 1671481984.0000 - val_mae: 30241.9766\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2800404224.0000 - mae: 39996.0391 - val_loss: 1665755392.0000 - val_mae: 30200.1895\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2769075712.0000 - mae: 39687.7109 - val_loss: 1660367744.0000 - val_mae: 30148.1250\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2754565120.0000 - mae: 39660.7812 - val_loss: 1655106304.0000 - val_mae: 30105.2168\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2759992576.0000 - mae: 39695.2266 - val_loss: 1649930752.0000 - val_mae: 30061.0098\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2741743360.0000 - mae: 39609.5078 - val_loss: 1645028096.0000 - val_mae: 30026.1484\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 4s 313ms/step - loss: 2735308032.0000 - mae: 39534.5000 - val_loss: 1640518016.0000 - val_mae: 29987.5859\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 4s 313ms/step - loss: 2743055360.0000 - mae: 39598.0547 - val_loss: 1636352896.0000 - val_mae: 29949.5488\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 2717020928.0000 - mae: 39480.9688 - val_loss: 1631964416.0000 - val_mae: 29914.0000\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 2738066176.0000 - mae: 39557.4648 - val_loss: 1628382976.0000 - val_mae: 29879.5410\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 4s 316ms/step - loss: 2725108224.0000 - mae: 39491.9648 - val_loss: 1624737024.0000 - val_mae: 29847.5469\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 2711462656.0000 - mae: 39361.1992 - val_loss: 1620910592.0000 - val_mae: 29813.9941\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 2720043776.0000 - mae: 39444.5391 - val_loss: 1617447168.0000 - val_mae: 29782.9004\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2689732864.0000 - mae: 39261.4375 - val_loss: 1614186112.0000 - val_mae: 29762.6523\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2717812992.0000 - mae: 39422.7031 - val_loss: 1610234496.0000 - val_mae: 29731.0840\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2724396032.0000 - mae: 39449.7227 - val_loss: 1606697728.0000 - val_mae: 29700.1016\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2687545856.0000 - mae: 39297.0781 - val_loss: 1603339264.0000 - val_mae: 29672.7070\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2712034304.0000 - mae: 39380.1758 - val_loss: 1600269056.0000 - val_mae: 29642.6973\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2702542080.0000 - mae: 39336.6094 - val_loss: 1597705856.0000 - val_mae: 29618.7090\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 2696230144.0000 - mae: 39344.2617 - val_loss: 1594691328.0000 - val_mae: 29592.7402\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2704877312.0000 - mae: 39316.6523 - val_loss: 1591905792.0000 - val_mae: 29570.3887\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2691140608.0000 - mae: 39282.0664 - val_loss: 1589143296.0000 - val_mae: 29549.5605\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2696226560.0000 - mae: 39329.3984 - val_loss: 1586578816.0000 - val_mae: 29524.1328\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2675324416.0000 - mae: 39154.5078 - val_loss: 1584089856.0000 - val_mae: 29505.4023\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2674119168.0000 - mae: 39164.2539 - val_loss: 1581702400.0000 - val_mae: 29487.5781\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 2667974912.0000 - mae: 39182.3320 - val_loss: 1579448448.0000 - val_mae: 29468.4141\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2669382144.0000 - mae: 39141.3906 - val_loss: 1576890368.0000 - val_mae: 29446.0391\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2671531264.0000 - mae: 39119.3789 - val_loss: 1574002304.0000 - val_mae: 29423.8730\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2666266880.0000 - mae: 39089.9922 - val_loss: 1571602048.0000 - val_mae: 29399.7324\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2673871872.0000 - mae: 39218.1758 - val_loss: 1569885312.0000 - val_mae: 29385.7812\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2657745664.0000 - mae: 39001.1250 - val_loss: 1568358400.0000 - val_mae: 29375.9609\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2647573760.0000 - mae: 38958.0039 - val_loss: 1566454912.0000 - val_mae: 29355.5879\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2649621248.0000 - mae: 38990.2227 - val_loss: 1564550656.0000 - val_mae: 29332.9648\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2652291584.0000 - mae: 39018.7227 - val_loss: 1561725440.0000 - val_mae: 29312.8457\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2660682496.0000 - mae: 39024.5625 - val_loss: 1559107456.0000 - val_mae: 29297.3125\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2666575104.0000 - mae: 39138.1094 - val_loss: 1556956928.0000 - val_mae: 29284.9922\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2654420992.0000 - mae: 39016.8203 - val_loss: 1555216000.0000 - val_mae: 29266.9062\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2650793984.0000 - mae: 39033.5430 - val_loss: 1553698944.0000 - val_mae: 29262.3184\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2646286592.0000 - mae: 38926.6562 - val_loss: 1552478720.0000 - val_mae: 29244.8145\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2638173440.0000 - mae: 38906.2305 - val_loss: 1550660992.0000 - val_mae: 29229.6719\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2641900544.0000 - mae: 38946.1758 - val_loss: 1548318080.0000 - val_mae: 29209.4375\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2634397696.0000 - mae: 38864.4922 - val_loss: 1546631808.0000 - val_mae: 29196.8203\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2643262720.0000 - mae: 39001.0977 - val_loss: 1545493248.0000 - val_mae: 29178.8613\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2646680320.0000 - mae: 39036.0664 - val_loss: 1544200064.0000 - val_mae: 29158.5957\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2665286400.0000 - mae: 39036.2227 - val_loss: 1542406912.0000 - val_mae: 29148.4277\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2619683840.0000 - mae: 38777.9766 - val_loss: 1540979456.0000 - val_mae: 29141.2285\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2626562048.0000 - mae: 38840.8164 - val_loss: 1539555456.0000 - val_mae: 29130.1680\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2630733312.0000 - mae: 38829.2578 - val_loss: 1537831936.0000 - val_mae: 29114.2500\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2619724288.0000 - mae: 38793.7227 - val_loss: 1536623232.0000 - val_mae: 29095.9980\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 2621417728.0000 - mae: 38876.9297 - val_loss: 1534781184.0000 - val_mae: 29082.4746\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2621293824.0000 - mae: 38758.0703 - val_loss: 1533096192.0000 - val_mae: 29073.5586\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2617765632.0000 - mae: 38807.6523 - val_loss: 1532526720.0000 - val_mae: 29066.7617\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2624247040.0000 - mae: 38880.7305 - val_loss: 1531535488.0000 - val_mae: 29060.2988\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2626116352.0000 - mae: 38859.7812 - val_loss: 1529694208.0000 - val_mae: 29045.1543\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2617212160.0000 - mae: 38787.4297 - val_loss: 1528333440.0000 - val_mae: 29029.3496\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2619273472.0000 - mae: 38815.6094 - val_loss: 1526452224.0000 - val_mae: 29013.6367\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2603479296.0000 - mae: 38722.5195 - val_loss: 1524855296.0000 - val_mae: 28995.8906\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2604692480.0000 - mae: 38683.0859 - val_loss: 1523751168.0000 - val_mae: 28998.9219\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 2633781248.0000 - mae: 38809.0820 - val_loss: 1522825600.0000 - val_mae: 29000.5098\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2627535616.0000 - mae: 38852.9375 - val_loss: 1521117056.0000 - val_mae: 28973.0117\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2611904512.0000 - mae: 38732.1836 - val_loss: 1519992704.0000 - val_mae: 28957.9102\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 4s 312ms/step - loss: 2617860864.0000 - mae: 38804.1016 - val_loss: 1518428544.0000 - val_mae: 28949.3652\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 2612500736.0000 - mae: 38776.5391 - val_loss: 1517352704.0000 - val_mae: 28953.0645\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2605795584.0000 - mae: 38728.2539 - val_loss: 1516360704.0000 - val_mae: 28931.4629\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2596593152.0000 - mae: 38681.6953 - val_loss: 1515247232.0000 - val_mae: 28914.8672\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2624444672.0000 - mae: 38851.6523 - val_loss: 1514517248.0000 - val_mae: 28915.6895\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2603699200.0000 - mae: 38683.4453 - val_loss: 1513079040.0000 - val_mae: 28909.0449\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2622928896.0000 - mae: 38898.5273 - val_loss: 1511746176.0000 - val_mae: 28895.0098\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2605250816.0000 - mae: 38684.9609 - val_loss: 1509825280.0000 - val_mae: 28881.2676\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2587658496.0000 - mae: 38599.1172 - val_loss: 1508989952.0000 - val_mae: 28880.1055\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2584956416.0000 - mae: 38608.3477 - val_loss: 1509131904.0000 - val_mae: 28871.6250\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2593780992.0000 - mae: 38654.9688 - val_loss: 1508328832.0000 - val_mae: 28863.3496\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2605249792.0000 - mae: 38665.7227 - val_loss: 1507212160.0000 - val_mae: 28857.0098\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2584520704.0000 - mae: 38541.2109 - val_loss: 1505104640.0000 - val_mae: 28842.7656\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2608627200.0000 - mae: 38792.7031 - val_loss: 1504039424.0000 - val_mae: 28835.0098\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2594821376.0000 - mae: 38581.1445 - val_loss: 1502883456.0000 - val_mae: 28812.2148\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 2586139392.0000 - mae: 38614.3750 - val_loss: 1501833216.0000 - val_mae: 28802.5430\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 2594620160.0000 - mae: 38592.8008 - val_loss: 1500298752.0000 - val_mae: 28794.7207\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2587067904.0000 - mae: 38592.7031 - val_loss: 1499931520.0000 - val_mae: 28792.1582\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2588921856.0000 - mae: 38611.3711 - val_loss: 1499240192.0000 - val_mae: 28793.0859\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2569723904.0000 - mae: 38484.9727 - val_loss: 1498985216.0000 - val_mae: 28793.3145\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2598038528.0000 - mae: 38661.4648 - val_loss: 1497220352.0000 - val_mae: 28765.6328\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2593005824.0000 - mae: 38599.9961 - val_loss: 1496598656.0000 - val_mae: 28757.8301\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2588921344.0000 - mae: 38593.4727 - val_loss: 1494793344.0000 - val_mae: 28744.2402\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2577433344.0000 - mae: 38604.0586 - val_loss: 1493898368.0000 - val_mae: 28736.2363\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2571689984.0000 - mae: 38504.6250 - val_loss: 1493374976.0000 - val_mae: 28730.4180\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2579226880.0000 - mae: 38516.1172 - val_loss: 1491699328.0000 - val_mae: 28722.2969\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2568519936.0000 - mae: 38507.4023 - val_loss: 1491170560.0000 - val_mae: 28717.5312\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2564878336.0000 - mae: 38467.3711 - val_loss: 1490457728.0000 - val_mae: 28710.8359\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2581961984.0000 - mae: 38559.0469 - val_loss: 1489210624.0000 - val_mae: 28705.6250\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2578909440.0000 - mae: 38561.6016 - val_loss: 1487932800.0000 - val_mae: 28698.2188\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2579358464.0000 - mae: 38543.3086 - val_loss: 1487072128.0000 - val_mae: 28681.1426\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2562662144.0000 - mae: 38443.7109 - val_loss: 1486391424.0000 - val_mae: 28676.0859\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2576539136.0000 - mae: 38482.3516 - val_loss: 1485004544.0000 - val_mae: 28677.2383\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2575633664.0000 - mae: 38564.0391 - val_loss: 1484169216.0000 - val_mae: 28674.4883\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2578416640.0000 - mae: 38597.0352 - val_loss: 1482689152.0000 - val_mae: 28669.2578\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2557557248.0000 - mae: 38411.3477 - val_loss: 1481974400.0000 - val_mae: 28649.1660\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2560842752.0000 - mae: 38444.3633 - val_loss: 1481243136.0000 - val_mae: 28646.7266\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2572779520.0000 - mae: 38458.9219 - val_loss: 1481022720.0000 - val_mae: 28635.1523\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2589572352.0000 - mae: 38574.4297 - val_loss: 1480751104.0000 - val_mae: 28630.7070\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2569748480.0000 - mae: 38470.1680 - val_loss: 1479961216.0000 - val_mae: 28622.1250\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2552730624.0000 - mae: 38393.8125 - val_loss: 1479126912.0000 - val_mae: 28615.0957\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2562303744.0000 - mae: 38397.3164 - val_loss: 1477716352.0000 - val_mae: 28605.7148\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2563755776.0000 - mae: 38414.4375 - val_loss: 1476066944.0000 - val_mae: 28600.2051\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2563372032.0000 - mae: 38420.3125 - val_loss: 1476114432.0000 - val_mae: 28603.2266\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2570625536.0000 - mae: 38556.2305 - val_loss: 1475638016.0000 - val_mae: 28600.5547\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2549715456.0000 - mae: 38406.3555 - val_loss: 1475373696.0000 - val_mae: 28594.6445\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2569733888.0000 - mae: 38444.1641 - val_loss: 1474114176.0000 - val_mae: 28583.5195\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2560815360.0000 - mae: 38463.5547 - val_loss: 1472877184.0000 - val_mae: 28573.1836\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2538794496.0000 - mae: 38237.0977 - val_loss: 1472828800.0000 - val_mae: 28565.6504\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 2548488704.0000 - mae: 38366.5312 - val_loss: 1471898752.0000 - val_mae: 28557.2227\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2571520512.0000 - mae: 38489.2930 - val_loss: 1470640768.0000 - val_mae: 28554.9746\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2544503808.0000 - mae: 38333.7891 - val_loss: 1469484416.0000 - val_mae: 28548.2188\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2582832384.0000 - mae: 38605.3828 - val_loss: 1468600192.0000 - val_mae: 28537.4121\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2547950592.0000 - mae: 38388.0508 - val_loss: 1467969024.0000 - val_mae: 28536.4844\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2563076864.0000 - mae: 38452.4805 - val_loss: 1468177536.0000 - val_mae: 28539.3672\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2560299520.0000 - mae: 38416.5508 - val_loss: 1467674880.0000 - val_mae: 28536.9941\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2548642560.0000 - mae: 38351.4258 - val_loss: 1466976640.0000 - val_mae: 28522.9707\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2546494720.0000 - mae: 38299.7695 - val_loss: 1466123264.0000 - val_mae: 28507.2656\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2564333568.0000 - mae: 38427.4648 - val_loss: 1465511936.0000 - val_mae: 28497.2246\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2548152320.0000 - mae: 38300.9805 - val_loss: 1464103040.0000 - val_mae: 28489.4277\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2555103488.0000 - mae: 38375.2344 - val_loss: 1463408640.0000 - val_mae: 28490.2188\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2541611776.0000 - mae: 38277.0781 - val_loss: 1462203392.0000 - val_mae: 28479.7129\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2546400256.0000 - mae: 38341.4805 - val_loss: 1461624320.0000 - val_mae: 28466.6133\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2555630336.0000 - mae: 38362.7930 - val_loss: 1460614784.0000 - val_mae: 28460.9082\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2539501824.0000 - mae: 38253.9609 - val_loss: 1459470720.0000 - val_mae: 28458.6113\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2553260800.0000 - mae: 38367.8711 - val_loss: 1460211840.0000 - val_mae: 28462.8848\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2533937152.0000 - mae: 38238.6328 - val_loss: 1458909824.0000 - val_mae: 28450.7227\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2539924992.0000 - mae: 38294.2617 - val_loss: 1458361984.0000 - val_mae: 28448.0039\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2550912256.0000 - mae: 38295.9531 - val_loss: 1457438080.0000 - val_mae: 28440.9414\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2551659520.0000 - mae: 38354.0078 - val_loss: 1457225088.0000 - val_mae: 28440.2012\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2560762368.0000 - mae: 38439.8984 - val_loss: 1457024000.0000 - val_mae: 28439.1348\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2527712256.0000 - mae: 38190.3320 - val_loss: 1455332992.0000 - val_mae: 28427.9316\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2564482304.0000 - mae: 38442.8125 - val_loss: 1454199168.0000 - val_mae: 28411.0508\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2530456832.0000 - mae: 38180.4531 - val_loss: 1453299200.0000 - val_mae: 28412.4863\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2544090112.0000 - mae: 38279.8438 - val_loss: 1453255808.0000 - val_mae: 28406.9766\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2539421440.0000 - mae: 38335.0078 - val_loss: 1452821888.0000 - val_mae: 28399.3750\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2544830976.0000 - mae: 38330.8828 - val_loss: 1451951744.0000 - val_mae: 28391.3926\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2527549952.0000 - mae: 38079.4922 - val_loss: 1451278720.0000 - val_mae: 28394.3301\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2539424256.0000 - mae: 38370.6367 - val_loss: 1450664960.0000 - val_mae: 28403.1953\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2532815104.0000 - mae: 38285.4062 - val_loss: 1450473344.0000 - val_mae: 28388.8398\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2533214464.0000 - mae: 38282.0312 - val_loss: 1450424576.0000 - val_mae: 28372.4902\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2531877632.0000 - mae: 38240.8867 - val_loss: 1448134400.0000 - val_mae: 28365.4824\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2537506048.0000 - mae: 38245.2266 - val_loss: 1447604480.0000 - val_mae: 28371.4062\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 4s 315ms/step - loss: 2538287616.0000 - mae: 38271.2969 - val_loss: 1446799488.0000 - val_mae: 28359.7402\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2537898240.0000 - mae: 38265.0273 - val_loss: 1446317568.0000 - val_mae: 28351.7324\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2541590528.0000 - mae: 38247.5703 - val_loss: 1447719168.0000 - val_mae: 28353.6035\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2514643712.0000 - mae: 38084.8477 - val_loss: 1445973888.0000 - val_mae: 28335.4805\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2538131200.0000 - mae: 38274.6992 - val_loss: 1444108288.0000 - val_mae: 28324.4023\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2536684800.0000 - mae: 38275.7930 - val_loss: 1444124160.0000 - val_mae: 28334.7070\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2529422848.0000 - mae: 38285.6094 - val_loss: 1444321152.0000 - val_mae: 28337.2500\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2519565568.0000 - mae: 38119.5156 - val_loss: 1443037952.0000 - val_mae: 28325.6289\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2545329408.0000 - mae: 38337.9609 - val_loss: 1441986560.0000 - val_mae: 28321.1016\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2518861824.0000 - mae: 38165.1094 - val_loss: 1441872640.0000 - val_mae: 28309.0176\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2529550592.0000 - mae: 38135.4336 - val_loss: 1439454208.0000 - val_mae: 28292.6738\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2539435008.0000 - mae: 38271.5039 - val_loss: 1439984512.0000 - val_mae: 28302.4199\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2516658688.0000 - mae: 38113.3750 - val_loss: 1440309888.0000 - val_mae: 28295.1582\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2512972800.0000 - mae: 38119.4844 - val_loss: 1437854592.0000 - val_mae: 28275.9062\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2515822336.0000 - mae: 38115.0469 - val_loss: 1437665664.0000 - val_mae: 28271.5215\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2528566784.0000 - mae: 38206.2656 - val_loss: 1437043712.0000 - val_mae: 28272.6602\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2532430080.0000 - mae: 38203.2656 - val_loss: 1436748928.0000 - val_mae: 28269.3887\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2510317312.0000 - mae: 38061.6914 - val_loss: 1435889792.0000 - val_mae: 28256.6953\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2518707968.0000 - mae: 38094.8633 - val_loss: 1435413632.0000 - val_mae: 28244.3887\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2515233280.0000 - mae: 38016.0430 - val_loss: 1433797120.0000 - val_mae: 28237.8789\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2496567040.0000 - mae: 37931.3672 - val_loss: 1433514880.0000 - val_mae: 28238.0273\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2506991104.0000 - mae: 38036.5508 - val_loss: 1433143552.0000 - val_mae: 28229.8066\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2507102208.0000 - mae: 38112.9727 - val_loss: 1433144192.0000 - val_mae: 28231.6055\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2521122048.0000 - mae: 38159.1328 - val_loss: 1432121984.0000 - val_mae: 28230.7617\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2519964928.0000 - mae: 38110.5430 - val_loss: 1430782080.0000 - val_mae: 28217.6562\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2501801216.0000 - mae: 38003.3242 - val_loss: 1431556480.0000 - val_mae: 28224.9941\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2517520640.0000 - mae: 38065.0742 - val_loss: 1430515968.0000 - val_mae: 28209.5078\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2532485632.0000 - mae: 38173.2070 - val_loss: 1427936512.0000 - val_mae: 28197.3066\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2519010816.0000 - mae: 38105.7070 - val_loss: 1427984256.0000 - val_mae: 28207.3848\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2489809920.0000 - mae: 37909.6523 - val_loss: 1427795712.0000 - val_mae: 28201.5449\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2527259648.0000 - mae: 38195.7695 - val_loss: 1428083712.0000 - val_mae: 28200.9883\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2508835584.0000 - mae: 38064.1797 - val_loss: 1426576128.0000 - val_mae: 28185.3066\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 2498647808.0000 - mae: 38021.6758 - val_loss: 1427057664.0000 - val_mae: 28178.4961\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2514481152.0000 - mae: 38051.6445 - val_loss: 1425557888.0000 - val_mae: 28166.8672\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2521065728.0000 - mae: 38128.8945 - val_loss: 1424943744.0000 - val_mae: 28170.5391\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2501760256.0000 - mae: 38000.4219 - val_loss: 1424618624.0000 - val_mae: 28177.5273\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2497964544.0000 - mae: 38032.7383 - val_loss: 1424374144.0000 - val_mae: 28168.3672\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2515419904.0000 - mae: 38141.0664 - val_loss: 1422835968.0000 - val_mae: 28167.3594\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2499744256.0000 - mae: 37967.5703 - val_loss: 1423333120.0000 - val_mae: 28155.8184\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 2502547712.0000 - mae: 38015.8398 - val_loss: 1422464128.0000 - val_mae: 28143.6348\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2504346624.0000 - mae: 37982.8125 - val_loss: 1420665600.0000 - val_mae: 28123.4629\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2516328448.0000 - mae: 38098.3164 - val_loss: 1419913344.0000 - val_mae: 28124.4473\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2510645248.0000 - mae: 38060.7812 - val_loss: 1420298112.0000 - val_mae: 28132.0566\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2496754432.0000 - mae: 38021.3203 - val_loss: 1419281536.0000 - val_mae: 28118.6855\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2500872704.0000 - mae: 38024.2656 - val_loss: 1418925056.0000 - val_mae: 28105.2832\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2505052672.0000 - mae: 37977.8086 - val_loss: 1417474304.0000 - val_mae: 28085.6211\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2476645632.0000 - mae: 37833.5234 - val_loss: 1416387456.0000 - val_mae: 28086.1934\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2503430656.0000 - mae: 37998.4727 - val_loss: 1415906432.0000 - val_mae: 28075.8281\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2510772736.0000 - mae: 38162.6133 - val_loss: 1416156800.0000 - val_mae: 28069.9414\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2503503872.0000 - mae: 38006.3203 - val_loss: 1415498752.0000 - val_mae: 28063.5410\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2503950592.0000 - mae: 37963.3789 - val_loss: 1414386304.0000 - val_mae: 28058.1074\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2479838720.0000 - mae: 37810.1445 - val_loss: 1413127040.0000 - val_mae: 28043.3164\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2504810752.0000 - mae: 37998.2578 - val_loss: 1413091584.0000 - val_mae: 28038.2480\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2501789952.0000 - mae: 38013.8320 - val_loss: 1412029312.0000 - val_mae: 28030.9199\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2495983616.0000 - mae: 37945.4844 - val_loss: 1411470976.0000 - val_mae: 28030.4531\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2487118592.0000 - mae: 37926.6133 - val_loss: 1409975168.0000 - val_mae: 28030.3457\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2500625920.0000 - mae: 37972.0859 - val_loss: 1410122240.0000 - val_mae: 28034.7363\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2498052096.0000 - mae: 38009.8281 - val_loss: 1408308224.0000 - val_mae: 28023.8359\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2509597696.0000 - mae: 38014.8125 - val_loss: 1407671552.0000 - val_mae: 28021.4668\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2485597440.0000 - mae: 37917.7070 - val_loss: 1406803840.0000 - val_mae: 28002.5254\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2488328192.0000 - mae: 37941.0625 - val_loss: 1405194880.0000 - val_mae: 27989.4727\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2495501312.0000 - mae: 37912.3125 - val_loss: 1405910784.0000 - val_mae: 27995.2441\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2490040320.0000 - mae: 37936.9453 - val_loss: 1405741056.0000 - val_mae: 27991.9492\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2492977920.0000 - mae: 37946.2930 - val_loss: 1404347776.0000 - val_mae: 27973.8457\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2475650816.0000 - mae: 37861.3320 - val_loss: 1403613312.0000 - val_mae: 27965.0996\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 4s 315ms/step - loss: 2492074240.0000 - mae: 37928.0352 - val_loss: 1403264256.0000 - val_mae: 27977.6582\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2488908032.0000 - mae: 37951.6953 - val_loss: 1403589888.0000 - val_mae: 27971.9766\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2491688448.0000 - mae: 37983.4375 - val_loss: 1401883776.0000 - val_mae: 27952.3359\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2492198912.0000 - mae: 37882.8711 - val_loss: 1399935744.0000 - val_mae: 27937.4727\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 2499041792.0000 - mae: 37977.3750 - val_loss: 1399211264.0000 - val_mae: 27948.2852\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 4s 313ms/step - loss: 2484384512.0000 - mae: 37894.7578 - val_loss: 1399483392.0000 - val_mae: 27930.1699\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2489198848.0000 - mae: 37909.9414 - val_loss: 1397743104.0000 - val_mae: 27910.8340\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2481865472.0000 - mae: 37767.1094 - val_loss: 1396138112.0000 - val_mae: 27903.3613\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2478636288.0000 - mae: 37901.7578 - val_loss: 1396392832.0000 - val_mae: 27910.5488\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2485977344.0000 - mae: 37888.3438 - val_loss: 1395848448.0000 - val_mae: 27893.5762\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2479863296.0000 - mae: 37795.8594 - val_loss: 1394585728.0000 - val_mae: 27889.1191\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 2487093760.0000 - mae: 37872.9336 - val_loss: 1394162432.0000 - val_mae: 27876.2168\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2484599040.0000 - mae: 37864.4414 - val_loss: 1391985536.0000 - val_mae: 27858.7812\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2465468160.0000 - mae: 37709.0078 - val_loss: 1391139456.0000 - val_mae: 27856.7148\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2473814528.0000 - mae: 37875.4297 - val_loss: 1391109504.0000 - val_mae: 27853.2754\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2481081856.0000 - mae: 37850.5781 - val_loss: 1390959744.0000 - val_mae: 27839.3730\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2480102656.0000 - mae: 37831.8555 - val_loss: 1389956352.0000 - val_mae: 27830.3633\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2475815168.0000 - mae: 37781.8398 - val_loss: 1387764736.0000 - val_mae: 27817.3789\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2480164864.0000 - mae: 37841.6055 - val_loss: 1389591936.0000 - val_mae: 27829.4043\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2483200768.0000 - mae: 37881.0977 - val_loss: 1387366144.0000 - val_mae: 27818.5586\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2467121408.0000 - mae: 37739.7695 - val_loss: 1385087232.0000 - val_mae: 27803.0820\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2469640192.0000 - mae: 37752.7891 - val_loss: 1385343616.0000 - val_mae: 27807.9121\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2456893440.0000 - mae: 37698.6680 - val_loss: 1384427776.0000 - val_mae: 27781.0156\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 2468298496.0000 - mae: 37776.4141 - val_loss: 1383154048.0000 - val_mae: 27756.5820\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2459649792.0000 - mae: 37720.4688 - val_loss: 1382879360.0000 - val_mae: 27763.9844\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2470778624.0000 - mae: 37761.6641 - val_loss: 1382641280.0000 - val_mae: 27768.6113\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2467902464.0000 - mae: 37731.3281 - val_loss: 1380591360.0000 - val_mae: 27738.4355\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2455549696.0000 - mae: 37679.7734 - val_loss: 1379443584.0000 - val_mae: 27721.1445\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2462482176.0000 - mae: 37701.4727 - val_loss: 1378310784.0000 - val_mae: 27733.2480\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2457911040.0000 - mae: 37754.7969 - val_loss: 1377483520.0000 - val_mae: 27706.3203\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2473944576.0000 - mae: 37759.6094 - val_loss: 1375952896.0000 - val_mae: 27692.9609\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 2453452800.0000 - mae: 37600.8203 - val_loss: 1374940800.0000 - val_mae: 27688.7930\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2457767424.0000 - mae: 37662.7422 - val_loss: 1375174272.0000 - val_mae: 27678.0371\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2462829568.0000 - mae: 37642.8945 - val_loss: 1373507584.0000 - val_mae: 27667.3223\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 2456247296.0000 - mae: 37703.3750 - val_loss: 1370635008.0000 - val_mae: 27645.2168\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 2490105088.0000 - mae: 37880.4102 - val_loss: 1371024256.0000 - val_mae: 27639.6602\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 2476628992.0000 - mae: 37752.0625 - val_loss: 1369254656.0000 - val_mae: 27637.9785\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2454229248.0000 - mae: 37580.0391 - val_loss: 1368450816.0000 - val_mae: 27622.4980\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2453394688.0000 - mae: 37668.1758 - val_loss: 1368101760.0000 - val_mae: 27627.2285\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2445591808.0000 - mae: 37607.8867 - val_loss: 1365803776.0000 - val_mae: 27602.5098\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 2443369216.0000 - mae: 37566.9492 - val_loss: 1364092288.0000 - val_mae: 27581.5605\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2445059072.0000 - mae: 37572.9766 - val_loss: 1364179840.0000 - val_mae: 27572.7012\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2464990720.0000 - mae: 37578.0625 - val_loss: 1362244992.0000 - val_mae: 27560.0176\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2465664512.0000 - mae: 37702.0938 - val_loss: 1360875776.0000 - val_mae: 27558.5234\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2456809728.0000 - mae: 37656.3477 - val_loss: 1359539712.0000 - val_mae: 27545.9453\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2446809856.0000 - mae: 37572.1602 - val_loss: 1360212224.0000 - val_mae: 27509.7402\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2444353792.0000 - mae: 37608.3945 - val_loss: 1356610304.0000 - val_mae: 27490.0684\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2474127872.0000 - mae: 37730.0195 - val_loss: 1356950784.0000 - val_mae: 27496.1055\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2453971456.0000 - mae: 37595.5234 - val_loss: 1355900928.0000 - val_mae: 27492.6465\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2425901568.0000 - mae: 37377.8750 - val_loss: 1353352832.0000 - val_mae: 27473.5098\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2436942080.0000 - mae: 37482.6680 - val_loss: 1352049024.0000 - val_mae: 27443.2754\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2435531520.0000 - mae: 37486.9453 - val_loss: 1351904640.0000 - val_mae: 27442.2812\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2419126784.0000 - mae: 37358.6094 - val_loss: 1349249920.0000 - val_mae: 27427.4883\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2446583296.0000 - mae: 37531.4688 - val_loss: 1347778176.0000 - val_mae: 27420.5508\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2422573312.0000 - mae: 37494.3320 - val_loss: 1348755968.0000 - val_mae: 27425.5664\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2425181696.0000 - mae: 37434.4805 - val_loss: 1346533376.0000 - val_mae: 27384.1191\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2424523776.0000 - mae: 37432.9180 - val_loss: 1344957952.0000 - val_mae: 27365.8027\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2426861312.0000 - mae: 37438.0703 - val_loss: 1343549184.0000 - val_mae: 27362.9727\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2441454080.0000 - mae: 37416.1680 - val_loss: 1342344832.0000 - val_mae: 27357.2363\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2432649472.0000 - mae: 37414.3555 - val_loss: 1341742976.0000 - val_mae: 27346.9004\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2415188992.0000 - mae: 37304.6172 - val_loss: 1340088064.0000 - val_mae: 27323.2363\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2433878528.0000 - mae: 37429.3672 - val_loss: 1337766528.0000 - val_mae: 27293.2812\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2419429632.0000 - mae: 37330.8438 - val_loss: 1336748544.0000 - val_mae: 27301.6230\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2420541696.0000 - mae: 37309.7188 - val_loss: 1334468736.0000 - val_mae: 27266.8652\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2419034368.0000 - mae: 37316.5938 - val_loss: 1334000000.0000 - val_mae: 27243.6875\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2414513408.0000 - mae: 37311.9492 - val_loss: 1333074816.0000 - val_mae: 27236.4844\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2415327488.0000 - mae: 37352.1133 - val_loss: 1329945856.0000 - val_mae: 27223.8750\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 4s 314ms/step - loss: 2426042880.0000 - mae: 37374.4688 - val_loss: 1328966528.0000 - val_mae: 27214.9355\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2405684736.0000 - mae: 37232.5352 - val_loss: 1327991808.0000 - val_mae: 27210.6504\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2411855104.0000 - mae: 37282.0742 - val_loss: 1325758848.0000 - val_mae: 27194.0234\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2422092032.0000 - mae: 37367.6289 - val_loss: 1324147584.0000 - val_mae: 27176.7363\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2412675584.0000 - mae: 37285.1992 - val_loss: 1322952448.0000 - val_mae: 27150.2520\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2419540736.0000 - mae: 37369.9570 - val_loss: 1323623808.0000 - val_mae: 27133.3652\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2420524288.0000 - mae: 37310.4414 - val_loss: 1319178624.0000 - val_mae: 27097.0859\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2400277504.0000 - mae: 37241.2500 - val_loss: 1317636992.0000 - val_mae: 27099.3555\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2408068864.0000 - mae: 37252.6133 - val_loss: 1316505088.0000 - val_mae: 27083.9043\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2415343872.0000 - mae: 37281.7734 - val_loss: 1317160704.0000 - val_mae: 27074.8711\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2400411392.0000 - mae: 37315.5586 - val_loss: 1316969984.0000 - val_mae: 27053.7012\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2392504576.0000 - mae: 37130.4609 - val_loss: 1311134208.0000 - val_mae: 27030.6602\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2392805632.0000 - mae: 37116.5273 - val_loss: 1311122816.0000 - val_mae: 27026.8359\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2405695232.0000 - mae: 37250.0742 - val_loss: 1309210624.0000 - val_mae: 27023.8789\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2404275712.0000 - mae: 37254.2148 - val_loss: 1309046016.0000 - val_mae: 27009.9531\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2402225152.0000 - mae: 37190.2930 - val_loss: 1306774144.0000 - val_mae: 26980.0039\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2411417088.0000 - mae: 37297.8984 - val_loss: 1304631808.0000 - val_mae: 26957.3535\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2369780992.0000 - mae: 37003.3125 - val_loss: 1303044096.0000 - val_mae: 26948.6133\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2392694528.0000 - mae: 37168.0859 - val_loss: 1301794560.0000 - val_mae: 26921.7363\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2395440384.0000 - mae: 37188.3125 - val_loss: 1300306560.0000 - val_mae: 26902.2871\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2377940224.0000 - mae: 36982.5195 - val_loss: 1298040320.0000 - val_mae: 26883.8477\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2400868352.0000 - mae: 37241.2383 - val_loss: 1296639104.0000 - val_mae: 26858.1797\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2368783360.0000 - mae: 36937.3594 - val_loss: 1295002752.0000 - val_mae: 26844.3613\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2382487552.0000 - mae: 37021.3086 - val_loss: 1292856832.0000 - val_mae: 26840.5039\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2386548736.0000 - mae: 37061.1992 - val_loss: 1292113664.0000 - val_mae: 26832.5195\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2369907200.0000 - mae: 37000.6523 - val_loss: 1291670272.0000 - val_mae: 26820.4512\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2392593408.0000 - mae: 37125.4609 - val_loss: 1288906368.0000 - val_mae: 26790.7715\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2371061504.0000 - mae: 36974.4609 - val_loss: 1288387712.0000 - val_mae: 26784.0332\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2379286272.0000 - mae: 37026.4961 - val_loss: 1284875520.0000 - val_mae: 26755.7871\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2373551872.0000 - mae: 36919.0391 - val_loss: 1285427712.0000 - val_mae: 26751.0586\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2362770688.0000 - mae: 36901.5391 - val_loss: 1281370624.0000 - val_mae: 26723.4668\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2369420288.0000 - mae: 36990.0469 - val_loss: 1281407488.0000 - val_mae: 26719.4121\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2371651072.0000 - mae: 36959.7461 - val_loss: 1279252096.0000 - val_mae: 26697.7168\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2387336960.0000 - mae: 36990.7070 - val_loss: 1276305408.0000 - val_mae: 26681.4121\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 4s 326ms/step - loss: 2365436672.0000 - mae: 36922.6133 - val_loss: 1275982080.0000 - val_mae: 26656.7832\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 4s 320ms/step - loss: 2387201536.0000 - mae: 37018.7930 - val_loss: 1273239296.0000 - val_mae: 26621.3105\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 4s 319ms/step - loss: 2371318272.0000 - mae: 36976.1992 - val_loss: 1270238080.0000 - val_mae: 26600.5605\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2347331328.0000 - mae: 36790.3750 - val_loss: 1271411968.0000 - val_mae: 26601.8262\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2357883904.0000 - mae: 36797.7695 - val_loss: 1269319680.0000 - val_mae: 26587.2969\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2368749312.0000 - mae: 36963.9219 - val_loss: 1266090752.0000 - val_mae: 26569.6992\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 2362674176.0000 - mae: 36864.0781 - val_loss: 1265005440.0000 - val_mae: 26550.0684\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 4s 312ms/step - loss: 2354069504.0000 - mae: 36828.3438 - val_loss: 1262420608.0000 - val_mae: 26517.7422\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2345051136.0000 - mae: 36730.4180 - val_loss: 1260626816.0000 - val_mae: 26491.5137\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2352652800.0000 - mae: 36785.8984 - val_loss: 1260105088.0000 - val_mae: 26485.7344\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2357093120.0000 - mae: 36746.2461 - val_loss: 1258163072.0000 - val_mae: 26456.5449\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2347259904.0000 - mae: 36689.1875 - val_loss: 1256369920.0000 - val_mae: 26434.2344\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2331309312.0000 - mae: 36665.0156 - val_loss: 1253777152.0000 - val_mae: 26420.5625\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2345408256.0000 - mae: 36748.6992 - val_loss: 1252099328.0000 - val_mae: 26418.7500\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2344709376.0000 - mae: 36735.4375 - val_loss: 1249985280.0000 - val_mae: 26379.9961\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2345504000.0000 - mae: 36751.2773 - val_loss: 1248229632.0000 - val_mae: 26349.7617\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2354175488.0000 - mae: 36649.4023 - val_loss: 1246694912.0000 - val_mae: 26333.7188\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2335331072.0000 - mae: 36661.7500 - val_loss: 1245943296.0000 - val_mae: 26330.1406\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2328177152.0000 - mae: 36581.5234 - val_loss: 1243328512.0000 - val_mae: 26293.3438\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2342628864.0000 - mae: 36669.1562 - val_loss: 1240711168.0000 - val_mae: 26274.3730\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2360295936.0000 - mae: 36837.5430 - val_loss: 1238480128.0000 - val_mae: 26250.9922\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2319490048.0000 - mae: 36524.5000 - val_loss: 1235195136.0000 - val_mae: 26207.5703\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2323374848.0000 - mae: 36587.1719 - val_loss: 1233306752.0000 - val_mae: 26182.8027\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2320279808.0000 - mae: 36587.0977 - val_loss: 1231720448.0000 - val_mae: 26174.5996\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2319610624.0000 - mae: 36554.4688 - val_loss: 1231313920.0000 - val_mae: 26156.3652\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2301328384.0000 - mae: 36374.6367 - val_loss: 1227630080.0000 - val_mae: 26122.5195\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2325970688.0000 - mae: 36594.2734 - val_loss: 1225431808.0000 - val_mae: 26098.7344\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2343725568.0000 - mae: 36690.8633 - val_loss: 1224236160.0000 - val_mae: 26100.8965\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2307286272.0000 - mae: 36472.2852 - val_loss: 1222846336.0000 - val_mae: 26085.6348\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2302181888.0000 - mae: 36360.1680 - val_loss: 1219119104.0000 - val_mae: 26037.0879\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2328839936.0000 - mae: 36582.8828 - val_loss: 1217641216.0000 - val_mae: 26021.3652\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2304387072.0000 - mae: 36397.9297 - val_loss: 1214379520.0000 - val_mae: 25994.2324\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2286817792.0000 - mae: 36333.9453 - val_loss: 1215006080.0000 - val_mae: 25983.8242\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 2325323264.0000 - mae: 36561.8828 - val_loss: 1211434496.0000 - val_mae: 25942.6621\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 2304458496.0000 - mae: 36417.7070 - val_loss: 1208888704.0000 - val_mae: 25909.5742\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2315929600.0000 - mae: 36379.5039 - val_loss: 1204671872.0000 - val_mae: 25889.6484\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2302493440.0000 - mae: 36326.3398 - val_loss: 1202717568.0000 - val_mae: 25865.9180\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2296078336.0000 - mae: 36307.3438 - val_loss: 1201402240.0000 - val_mae: 25839.6426\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2272146432.0000 - mae: 36219.4336 - val_loss: 1197998592.0000 - val_mae: 25801.9844\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2281750272.0000 - mae: 36201.3359 - val_loss: 1197369216.0000 - val_mae: 25793.8477\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2304965888.0000 - mae: 36304.4727 - val_loss: 1192348160.0000 - val_mae: 25750.3164\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2280615168.0000 - mae: 36183.5117 - val_loss: 1190777216.0000 - val_mae: 25728.7539\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2284618496.0000 - mae: 36268.5469 - val_loss: 1188809984.0000 - val_mae: 25707.3047\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2291391232.0000 - mae: 36232.3047 - val_loss: 1186151040.0000 - val_mae: 25670.2617\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2293353216.0000 - mae: 36288.0977 - val_loss: 1184952960.0000 - val_mae: 25650.0293\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2275280896.0000 - mae: 36138.8867 - val_loss: 1181822592.0000 - val_mae: 25621.9121\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2281469184.0000 - mae: 36171.0781 - val_loss: 1180133376.0000 - val_mae: 25587.2363\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2275930880.0000 - mae: 36166.0312 - val_loss: 1176058240.0000 - val_mae: 25555.8438\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2262608128.0000 - mae: 36079.3711 - val_loss: 1174818048.0000 - val_mae: 25539.4824\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2269917696.0000 - mae: 36051.2969 - val_loss: 1172748288.0000 - val_mae: 25499.0801\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2270360832.0000 - mae: 36108.8008 - val_loss: 1169418880.0000 - val_mae: 25481.9531\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2284835072.0000 - mae: 36243.9883 - val_loss: 1168692864.0000 - val_mae: 25468.3672\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2266762496.0000 - mae: 36101.4922 - val_loss: 1162788224.0000 - val_mae: 25411.7305\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2260792320.0000 - mae: 36009.6445 - val_loss: 1164020736.0000 - val_mae: 25410.5840\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2261721856.0000 - mae: 36034.6758 - val_loss: 1159304192.0000 - val_mae: 25353.2344\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2273548544.0000 - mae: 36083.5273 - val_loss: 1157437952.0000 - val_mae: 25325.0918\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2257633024.0000 - mae: 35985.6602 - val_loss: 1156084096.0000 - val_mae: 25309.8535\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2247179776.0000 - mae: 35899.4297 - val_loss: 1151208960.0000 - val_mae: 25259.5664\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2241144576.0000 - mae: 35837.0664 - val_loss: 1148436480.0000 - val_mae: 25222.7578\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2249863680.0000 - mae: 35889.4609 - val_loss: 1145288576.0000 - val_mae: 25191.3281\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2250221568.0000 - mae: 35946.0273 - val_loss: 1144680832.0000 - val_mae: 25192.4551\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 2217681920.0000 - mae: 35735.7695 - val_loss: 1141126272.0000 - val_mae: 25153.5684\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 4s 311ms/step - loss: 2248898560.0000 - mae: 35976.2305 - val_loss: 1139143168.0000 - val_mae: 25116.5723\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 4s 306ms/step - loss: 2232920576.0000 - mae: 35828.4414 - val_loss: 1135117952.0000 - val_mae: 25076.2734\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 2234377984.0000 - mae: 35848.1367 - val_loss: 1133724416.0000 - val_mae: 25067.7559\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 2228814336.0000 - mae: 35777.7773 - val_loss: 1131324672.0000 - val_mae: 25036.1250\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 4s 321ms/step - loss: 2257825280.0000 - mae: 35958.7109 - val_loss: 1128296448.0000 - val_mae: 25003.2520\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 4s 312ms/step - loss: 2236176128.0000 - mae: 35770.2812 - val_loss: 1127248128.0000 - val_mae: 24996.3887\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2221820416.0000 - mae: 35718.9883 - val_loss: 1122640768.0000 - val_mae: 24933.4824\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2219664384.0000 - mae: 35685.9609 - val_loss: 1121603584.0000 - val_mae: 24914.6797\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2220889600.0000 - mae: 35698.4883 - val_loss: 1116314112.0000 - val_mae: 24861.1016\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2222143488.0000 - mae: 35632.3672 - val_loss: 1113911552.0000 - val_mae: 24839.9160\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2199650304.0000 - mae: 35566.9844 - val_loss: 1113561088.0000 - val_mae: 24836.6660\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2199057408.0000 - mae: 35512.5000 - val_loss: 1109704704.0000 - val_mae: 24785.1465\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2213178368.0000 - mae: 35623.4688 - val_loss: 1104955904.0000 - val_mae: 24733.9004\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2212999424.0000 - mae: 35599.1445 - val_loss: 1104118784.0000 - val_mae: 24725.7207\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2198680832.0000 - mae: 35563.7969 - val_loss: 1101537408.0000 - val_mae: 24694.5469\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2223165696.0000 - mae: 35648.5625 - val_loss: 1098958208.0000 - val_mae: 24671.3125\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2191556864.0000 - mae: 35475.5664 - val_loss: 1097111552.0000 - val_mae: 24658.0820\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2188823296.0000 - mae: 35459.2461 - val_loss: 1094554240.0000 - val_mae: 24612.5332\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2198749440.0000 - mae: 35474.8594 - val_loss: 1090636160.0000 - val_mae: 24570.9883\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2203574528.0000 - mae: 35615.4688 - val_loss: 1089974912.0000 - val_mae: 24555.0293\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 2188468224.0000 - mae: 35431.0781 - val_loss: 1087486976.0000 - val_mae: 24520.6895\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 4s 315ms/step - loss: 2159852288.0000 - mae: 35185.7031 - val_loss: 1083248128.0000 - val_mae: 24474.4785\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 2179121152.0000 - mae: 35285.1016 - val_loss: 1081774592.0000 - val_mae: 24460.7695\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 2178069248.0000 - mae: 35329.8438 - val_loss: 1078036864.0000 - val_mae: 24425.3125\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 4s 300ms/step - loss: 2172702976.0000 - mae: 35337.2305 - val_loss: 1076480512.0000 - val_mae: 24409.2969\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 2185523456.0000 - mae: 35375.9805 - val_loss: 1073932928.0000 - val_mae: 24377.5977\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2181504256.0000 - mae: 35339.7578 - val_loss: 1073586112.0000 - val_mae: 24356.9160\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 2174314496.0000 - mae: 35322.5195 - val_loss: 1069645888.0000 - val_mae: 24310.0273\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 4s 298ms/step - loss: 2174874368.0000 - mae: 35276.8164 - val_loss: 1067298304.0000 - val_mae: 24279.4141\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 2169052928.0000 - mae: 35273.3203 - val_loss: 1063143424.0000 - val_mae: 24236.9473\n",
      "CPU times: total: 44min 18s\n",
      "Wall time: 30min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x251942c7e50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=500,\n",
    "          batch_size=10000,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1dae4089-2844-45af-898e-5a57ace0d58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3531/3531 [==============================] - 11s 3ms/step\n",
      "1177/1177 [==============================] - 4s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ab54361-7c8a-4092-a20d-e587abb8b8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490502203948806"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9478782466991876"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32383.959546027105"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32605.798408790768"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "metrics.r2_score(y_test, y_test_pred)\n",
    "\n",
    "# RMSE\n",
    "np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c130f51-7f46-461c-8076-a936537b3bf7",
   "metadata": {},
   "source": [
    "# Part 3 Discussion, Conclusion\n",
    "\n",
    "## 3.1 Model Performance Overview\n",
    "\n",
    "|Model|R2 Train score|R2 Test score|RMSE Train Score|RMSE Test Score|Comments|\n",
    "|---|---|---|---|---|---|\n",
    "|Linear Regression|*Cross validation R2 score*<br>-3.6e+17|0.932|36897|37172|Largely Overfitting comparing the crossval R2 score to test R2 score|\n",
    "|RidgeCV|0.934|0.932|36889|37157|Improved performance compared to Linear Regression|\n",
    "|LassoCV|0.896|0.895|46364|46256|Improved performance compared to Linear Regression|\n",
    "|Random Forest|0.951|0.936|31675|36282|Improved performance compared to Linear Regression|\n",
    "|XGBoost|0.977|0.965|21814|26742|Best Performing Model|\n",
    "|Seq Neural Network|0.949|0.948|32384|32605|Improved performance compared to Linear Regression|\n",
    "\n",
    "\n",
    "<br><br>\n",
    "**Comments**<br>\n",
    "<code>XGBoost</code> gave the best performance with R2 score of 0.96 and RMSE score of 26742 (meaning the predicted price differe $26K +/- from actual HDB resale price)\n",
    "\n",
    "Housing prices are typically non-linearly related to their predictors, meaning that a linear model may not be able to capture the complex relationships between the predictors and the response variable. XGBoost is a tree-based model that can handle non-linearity well by partitioning the data into regions with different response values and using decision trees to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab377dc8-7f86-49dd-8dd9-75ca63288458",
   "metadata": {},
   "source": [
    "## 3.2 Analysing Features\n",
    "\n",
    "This segment will be focusing on RidgeCV coefficient values and XGBoost F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9566c-ee0c-4c07-bb4d-c7df002f6f7b",
   "metadata": {},
   "source": [
    "### RidgeCV Coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b171238-2f07-4144-b8db-50cd4c2a470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeCV_coef_df = feature_coef_(RidgeCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cba1924-670e-461c-9545-59125ac5ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeCV_coef_df['absolute_coef'] = np.abs(RidgeCV.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b08dc25c-5efb-4c10-92b7-dcb4888a49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dataframe based on absolute coeffecient value\n",
    "RidgeCV_coef_df = RidgeCV_coef_df.sort_values(by=['absolute_coef'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55b16997-277a-4687-ac7b-4fd5b85cb029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coeffiecient</th>\n",
       "      <th>absolute_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>flat_model_Terrace</td>\n",
       "      <td>390251.947720</td>\n",
       "      <td>390251.947720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>street_name_ANG MO KIO AVE 2</td>\n",
       "      <td>228461.643372</td>\n",
       "      <td>228461.643372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>street_name_MOH GUAN TER</td>\n",
       "      <td>215310.670183</td>\n",
       "      <td>215310.670183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>street_name_KIM CHENG ST</td>\n",
       "      <td>214612.594616</td>\n",
       "      <td>214612.594616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>street_name_SENG POH RD</td>\n",
       "      <td>197039.973517</td>\n",
       "      <td>197039.973517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>street_name_KIM PONG RD</td>\n",
       "      <td>196100.268026</td>\n",
       "      <td>196100.268026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>street_name_LIM LIAK ST</td>\n",
       "      <td>191056.207851</td>\n",
       "      <td>191056.207851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>pri_sch_name_Henry Park Primary School</td>\n",
       "      <td>173718.940304</td>\n",
       "      <td>173718.940304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>street_name_TIONG BAHRU RD</td>\n",
       "      <td>173658.269001</td>\n",
       "      <td>173658.269001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>street_name_SERANGOON AVE 2</td>\n",
       "      <td>173579.657389</td>\n",
       "      <td>173579.657389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>sec_sch_name_CHIJ Katong Convent</td>\n",
       "      <td>160118.720954</td>\n",
       "      <td>160118.720954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>street_name_MARSILING RD</td>\n",
       "      <td>-160064.121972</td>\n",
       "      <td>160064.121972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>street_name_DOVER CL EAST</td>\n",
       "      <td>159397.643557</td>\n",
       "      <td>159397.643557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>street_name_SERANGOON AVE 3</td>\n",
       "      <td>153825.595254</td>\n",
       "      <td>153825.595254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>mrt_name_Labrador Park</td>\n",
       "      <td>146607.708995</td>\n",
       "      <td>146607.708995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>street_name_ZION RD</td>\n",
       "      <td>145215.717848</td>\n",
       "      <td>145215.717848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>street_name_CLARENCE LANE</td>\n",
       "      <td>144148.651804</td>\n",
       "      <td>144148.651804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>street_name_SERANGOON CTRL DR</td>\n",
       "      <td>139721.617730</td>\n",
       "      <td>139721.617730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>street_name_BOON LAY PL</td>\n",
       "      <td>138780.215172</td>\n",
       "      <td>138780.215172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>street_name_MARINE DR</td>\n",
       "      <td>137057.556151</td>\n",
       "      <td>137057.556151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Features   Coeffiecient  absolute_coef\n",
       "131                      flat_model_Terrace  390251.947720  390251.947720\n",
       "146            street_name_ANG MO KIO AVE 2  228461.643372  228461.643372\n",
       "449                street_name_MOH GUAN TER  215310.670183  215310.670183\n",
       "410                street_name_KIM CHENG ST  214612.594616  214612.594616\n",
       "513                 street_name_SENG POH RD  197039.973517  197039.973517\n",
       "413                 street_name_KIM PONG RD  196100.268026  196100.268026\n",
       "421                 street_name_LIM LIAK ST  191056.207851  191056.207851\n",
       "839  pri_sch_name_Henry Park Primary School  173718.940304  173718.940304\n",
       "600              street_name_TIONG BAHRU RD  173658.269001  173658.269001\n",
       "523             street_name_SERANGOON AVE 2  173579.657389  173579.657389\n",
       "973        sec_sch_name_CHIJ Katong Convent  160118.720954  160118.720954\n",
       "445                street_name_MARSILING RD -160064.121972  160064.121972\n",
       "291               street_name_DOVER CL EAST  159397.643557  159397.643557\n",
       "524             street_name_SERANGOON AVE 3  153825.595254  153825.595254\n",
       "734                  mrt_name_Labrador Park  146607.708995  146607.708995\n",
       "685                     street_name_ZION RD  145215.717848  145215.717848\n",
       "263               street_name_CLARENCE LANE  144148.651804  144148.651804\n",
       "527           street_name_SERANGOON CTRL DR  139721.617730  139721.617730\n",
       "191                 street_name_BOON LAY PL  138780.215172  138780.215172\n",
       "439                   street_name_MARINE DR  137057.556151  137057.556151"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 20 features\n",
    "RidgeCV_coef_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d22e4e7-7086-4178-8f56-1b9244ec8247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coeffiecient</th>\n",
       "      <th>absolute_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>mrt_name_Tampines West</td>\n",
       "      <td>-860.783644</td>\n",
       "      <td>860.783644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Tranc_YearMonth_2014-10-01</td>\n",
       "      <td>826.394799</td>\n",
       "      <td>826.394799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>street_name_CHOA CHU KANG AVE 7</td>\n",
       "      <td>781.642452</td>\n",
       "      <td>781.642452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>street_name_CHOA CHU KANG NTH 6</td>\n",
       "      <td>776.229955</td>\n",
       "      <td>776.229955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>sec_sch_name_Naval Base Secondary School</td>\n",
       "      <td>688.816588</td>\n",
       "      <td>688.816588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Tranc_YearMonth_2020-08-01</td>\n",
       "      <td>-664.721799</td>\n",
       "      <td>664.721799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>sec_sch_name_Edgefield Secondary School</td>\n",
       "      <td>-534.619162</td>\n",
       "      <td>534.619162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Tranc_YearMonth_2014-12-01</td>\n",
       "      <td>-498.736673</td>\n",
       "      <td>498.736673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tranc_YearMonth_2014-11-01</td>\n",
       "      <td>-496.507392</td>\n",
       "      <td>496.507392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>street_name_PASIR RIS ST 53</td>\n",
       "      <td>-491.943499</td>\n",
       "      <td>491.943499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>sec_sch_nearest_dist</td>\n",
       "      <td>465.797072</td>\n",
       "      <td>465.797072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>sec_sch_name_Northbrooks Secondary School</td>\n",
       "      <td>-315.101465</td>\n",
       "      <td>315.101465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tranc_YearMonth_2020-05-01</td>\n",
       "      <td>278.462239</td>\n",
       "      <td>278.462239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Tranc_YearMonth_2016-07-01</td>\n",
       "      <td>-272.679814</td>\n",
       "      <td>272.679814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>pri_sch_name_Yu Neng Primary School</td>\n",
       "      <td>-255.223877</td>\n",
       "      <td>255.223877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>street_name_CHOA CHU KANG ST 62</td>\n",
       "      <td>-229.927207</td>\n",
       "      <td>229.927207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>street_name_BEDOK NTH ST 4</td>\n",
       "      <td>-107.780383</td>\n",
       "      <td>107.780383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>sec_sch_name_Northland Secondary School</td>\n",
       "      <td>-70.011171</td>\n",
       "      <td>70.011171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>street_name_KELANTAN RD</td>\n",
       "      <td>54.940029</td>\n",
       "      <td>54.940029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>sec_sch_name_Pasir Ris Crest Secondary School</td>\n",
       "      <td>-3.924871</td>\n",
       "      <td>3.924871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Features  Coeffiecient  \\\n",
       "762                          mrt_name_Tampines West   -860.783644   \n",
       "30                       Tranc_YearMonth_2014-10-01    826.394799   \n",
       "248                 street_name_CHOA CHU KANG AVE 7    781.642452   \n",
       "254                 street_name_CHOA CHU KANG NTH 6    776.229955   \n",
       "1029       sec_sch_name_Naval Base Secondary School    688.816588   \n",
       "100                      Tranc_YearMonth_2020-08-01   -664.721799   \n",
       "995         sec_sch_name_Edgefield Secondary School   -534.619162   \n",
       "32                       Tranc_YearMonth_2014-12-01   -498.736673   \n",
       "31                       Tranc_YearMonth_2014-11-01   -496.507392   \n",
       "471                     street_name_PASIR RIS ST 53   -491.943499   \n",
       "1095                           sec_sch_nearest_dist    465.797072   \n",
       "1033      sec_sch_name_Northbrooks Secondary School   -315.101465   \n",
       "97                       Tranc_YearMonth_2020-05-01    278.462239   \n",
       "51                       Tranc_YearMonth_2016-07-01   -272.679814   \n",
       "949             pri_sch_name_Yu Neng Primary School   -255.223877   \n",
       "260                 street_name_CHOA CHU KANG ST 62   -229.927207   \n",
       "172                      street_name_BEDOK NTH ST 4   -107.780383   \n",
       "1034        sec_sch_name_Northland Secondary School    -70.011171   \n",
       "406                         street_name_KELANTAN RD     54.940029   \n",
       "1037  sec_sch_name_Pasir Ris Crest Secondary School     -3.924871   \n",
       "\n",
       "      absolute_coef  \n",
       "762      860.783644  \n",
       "30       826.394799  \n",
       "248      781.642452  \n",
       "254      776.229955  \n",
       "1029     688.816588  \n",
       "100      664.721799  \n",
       "995      534.619162  \n",
       "32       498.736673  \n",
       "31       496.507392  \n",
       "471      491.943499  \n",
       "1095     465.797072  \n",
       "1033     315.101465  \n",
       "97       278.462239  \n",
       "51       272.679814  \n",
       "949      255.223877  \n",
       "260      229.927207  \n",
       "172      107.780383  \n",
       "1034      70.011171  \n",
       "406       54.940029  \n",
       "1037       3.924871  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bottom 20 features\n",
    "RidgeCV_coef_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3dff96-3adb-40d6-96c7-aaf258ca7f79",
   "metadata": {},
   "source": [
    "**Comments**<br>\n",
    "\n",
    "After removing <code>address</code> as a feature used for modelling, other location-related feature <code>street_name</code> appear to significantly influence the HDB prices. <code>street_name</code> related categories features appear very frequently among the features with top 20 absolute coefficient value.\n",
    "\n",
    "That being said, we also noticed certain schools (e.g.Henry Park Primary School) and MRT stations (e.g. Labrador Park) have key influence on HDB prices as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96f85d-88e0-4adf-88dd-1014b3be791a",
   "metadata": {},
   "source": [
    "### XGBoost Feature Importance F-score\n",
    "\n",
    "The F-score is a measure of a feature's importance that takes into account both the number of times a feature is used to split the data and the magnitude of the improvement in the objective function resulting from each split.\n",
    "\n",
    "Features with higher F-scores are considered more important by XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b63d4dc7-e85c-4406-af45-518aacea5e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#View feature importance in predicting HDB resale prices\n",
    "xgb.plot_importance(xg_reg, max_num_features=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83c57a-5e4c-4bbd-800a-9d1a7d3b3690",
   "metadata": {},
   "source": [
    "Here we can notice that more features are realised to have strong predictive importance in HDB prices such as <code>transaction year</code> and <code>HDB-age</code>, which is no surprise as we are familiar that generally prices are generally increaseing over the years, and older HDB flats may tend to have lower resale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6ab19-1362-4e51-b89d-3236e024d765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
